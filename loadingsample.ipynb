{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_dropout': 0.0, 'activation_fn': 'gelu', 'attention_dropout': 0.0, 'attention_type': 'DilatedAttention', 'bos_token_id': 0, 'decoder_attention_heads': 12, 'decoder_ffn_embed_dim': 1280, 'decoder_layers': 12, 'decoder_normalize_before': True, 'deepnorm': False, 'dilated_ratio': [1, 2], 'drop_path_rate': 0.0, 'dropout': 0.0, 'embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_layers': 12, 'encoder_normalize_before': True, 'eos_token_id': 2, 'flash_attention': True, 'initializer_range': 0.02, 'layernorm_embedding': False, 'layernorm_eps': 1e-06, 'mask_token_id': 4, 'max_positions': 65536, 'max_rel_pos': 0, 'no_scale_embedding': True, 'normalize_output': True, 'num_attention_heads': 12, 'pad_token_id': 1, 'rel_pos_buckets': 0, 'segment_length': [2048, 4096], 'seq_parallel': False, 'subln': True, 'transformers_version': '4.44.2', 'vocab_size': 19, '_commit_hash': None, 'attn_implementation': None}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "from longnetLM.config.config import *\n",
    "from longnetLM.config.LongNetTokenizer import LongNetTokenizer\n",
    "\n",
    "config_path = \"longnetLM/config/config_0.1b\"\n",
    "vocab_path = \"longnetLM/config/vocab.txt\"\n",
    "tokenizer = LongNetTokenizer(vocab_path)\n",
    "config = LongnetConfig.from_pretrained(\n",
    "    config_path,\n",
    "    attention_type=\"DilatedAttention\",\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    mask_token_id=tokenizer.mask_token_id,\n",
    "    flash_attention=False,\n",
    "    segment_length='[2048,4096]', \n",
    "    dilated_ratio='[1,2]', \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build dataset \n",
    "from datasets import load_dataset\n",
    "\n",
    "def pack(_tokenizer,max_length,padding=\"max_length\",pad_to_multiple_of=None):\n",
    "    def padseq(line):\n",
    "        inputs=_tokenizer(line[\"seq\"], max_length=max_length, truncation=True,padding=padding,pad_to_multiple_of=pad_to_multiple_of)\n",
    "        return inputs\n",
    "    return padseq\n",
    "func=pack(tokenizer,26000,padding=\"max_length\")\n",
    "dataset_path=f\"{YOUR_DATASET_PATH_HERE}\"\n",
    "train_ds = load_dataset(\"csv\",data_files=f\"{dataset_path}/sars-sars2_26k_train.csv\").remove_columns(\"Unnamed: 0\")\n",
    "test_ds  = load_dataset(\"csv\",data_files=f\"{dataset_path}/sars-sars2_26k_test.csv\" ).remove_columns(\"Unnamed: 0\")\n",
    "eval_ds  = load_dataset(\"csv\",data_files=f\"{dataset_path}/sars-sars2_26k_eval.csv\" ).remove_columns(\"Unnamed: 0\")\n",
    "train_ds=train_ds.map(func,batched=True,num_proc=128)[\"train\"].remove_columns(\"seq\")\n",
    "test_ds=test_ds.map(func,batched=True,num_proc=128)[\"train\"].remove_columns(\"seq\")\n",
    "eval_ds=eval_ds.map(func,batched=True,num_proc=128)[\"train\"].remove_columns(\"seq\")\n",
    "\n",
    "output_path=f\"{YOUR_OUTPUT_PATH_HERE}\"\n",
    "perfix=\"SARS-SARS2_26k\"\n",
    "train_ds.save_to_disk(f\"{output_path}/{perfix}/trainset\", num_proc=128)\n",
    "eval_ds.save_to_disk( f\"{output_path}/{perfix}/evalset\" , num_proc=128)\n",
    "test_ds.save_to_disk( f\"{output_path}/{perfix}/testset\" , num_proc=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengyulong/opt/miniconda3/envs/ML/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#encoder\n",
    "from longnetLM.srcs.architecture.layers import *\n",
    "from longnetLM.srcs.LongNetLM import LongNetEncoderLM,LongNetDecoderLM,LongNetEncoderDecoderLM\n",
    "import torch\n",
    "device=\"cpu\"\n",
    "x=torch.randint(0,7,(2,26000),device=device)\n",
    "# emb=LongNetEmbeddings(config).to(dtype=torch.float16,device=device)\n",
    "# encoder=Encoder(config).to(dtype=torch.float16,device=device)\n",
    "# decoder=Decoder(config).to(dtype=torch.float16,device=device)\n",
    "# model=LongNetEncoderLM(config).to(dtype=torch.float16,device=device)\n",
    "# model=LongNetDecoderLM(config).to(dtype=torch.float16,device=device)\n",
    "model=LongNetEncoderDecoderLM(config).to(dtype=torch.float16,device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongNetEncoderDecoderLM(\n",
       "  (embedding): LongNetEmbeddings(\n",
       "    (word_embeddings): Embedding(19, 768, padding_idx=1)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (position_embeddings): Embedding(65536, 768, padding_idx=1)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x EncoderLayer(\n",
       "        (self_attn): DilatedAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (inner_attn_ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "        (ffn): FeedForwardNetwork(\n",
       "          (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (ffn_layernorm): LayerNorm((3072,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x DecoderLayer(\n",
       "        (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn): DilatedAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (inner_attn_ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (ffn): FeedForwardNetwork(\n",
       "          (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (fc1): Linear(in_features=768, out_features=1280, bias=True)\n",
       "          (fc2): Linear(in_features=1280, out_features=768, bias=True)\n",
       "          (ffn_layernorm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_count(m):\n",
    "    ttp=0\n",
    "    tp=0\n",
    "    for p in m.parameters():\n",
    "        c=p.numel()\n",
    "        if p.requires_grad == True:\n",
    "            ttp+=c\n",
    "        tp+=c\n",
    "    print(f\"Total trainable parameters: {ttp}\")\n",
    "    print(f\"Total parameters: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 187547904\n",
      "Total parameters: 187547904\n"
     ]
    }
   ],
   "source": [
    "p_count(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
